# -*- coding: utf-8 -*-
"""JUAN_DAVID_ORTEGA_TEST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tZxeOXcFrFVZa4cWaEcTC6zgX0XX60g0

# NAME: *JUAN DAVID ORTEGA*
## ROL: DATA SCIENTIST

### Libraries
"""

import pandas as pd

"""## Part 1 – Python Basics

### 1. Given the list of basket values, do the following:
- Print out whether each basket is small (basket value < £5), medium (£5 ≤ basket value < £10) or
large (basket value ≥ £10);
- Sum and print the value of the medium value baskets.
"""

basket_values = [3.43, 9.73, 7.56, 9.52, 15.23, 2.25, 6.44, 7.38]
medium_baskets = 0
for values in basket_values:
  if  values < 5:
    print(f'Basket value: {values} is a small basket')
  elif  5 <= values < 10:
    print(f'Basket value: {values} is a medium basket')
    medium_baskets += values
  else:
    print(f"Basket value: {values} is a large basket")

print(f"\nThe sum of medium value baskets is: {medium_baskets}")

"""### 2. You are given the following nested dictionaries, which represent items in a basket.  Do the following:
- Return the product name for item 7527;
- Return the total value of this basket;
- Add another entry for a product that costs £4.95, has ID 7524 and name ‘poppy seeds’
"""

basket = {'2624': {'price': 0.5, 'prod_name': 'salt'},
          '2894': {'price': 3.25, 'prod_name': 'yeast'},
          '7527': {'price': 2.5, 'prod_name': 'flour'}}

name = basket[str(7527)]['prod_name']

values = sum(item['price'] for item in basket.values())

basket['7524'] = {'price': 4.95, 'prod:name': 'poppy_seeds'}

print(f'The name of the item 7527 is: {name}')
print(f'The total value of this basket is: {values}')

"""### 3. Below is the source code for a function called ‘get_sql_string’.
```python
def get_sql_string(stores):
  store_names = [x.split(', ')[0] for x in stores]
  store_names = [x.replace(' ', '') for x in store_names]
  store_regions = [x.split(',')[1] for x in stores]
  locations = store_names + store_regions
  columns = ['sales' + x.lower() for x in locations]
  return ', '.join(columns)
```
- There is a bug in line 4. What should the line be?
- Assuming this bug was fixed, what would be returned if the following command was executed:
```python
    my_stores = ['Fulham Palace Rd, Hammersmith', 'Crown St, Reading', 'Leavesden Green, Watford']
    get_sql_string(my_stores)
```
- Write a function that:
  - accepts a list of strings as input;
  - returns an alphabetically ordered list of unique strings;
  - prints the string(s) with maximum length.
"""

def get_sql_string(stores):
  store_names = [x.split(', ')[0] for x in stores]
  store_names = [x.replace(' ', '') for x in store_names]
  store_regions = [x.split(', ')[1] for x in stores]
  locations = store_names + store_regions
  columns = ['sales' + x.lower() for x in locations]
  return ', '.join(columns)

def correct_string(string_list):
  new_list =  sorted(set(string_list))
  max_length = max(len(words) for words in new_list)

  print("Stings with max length:")
  for words in new_list:
    if len(words) == max_length:
      print(words)
  return new_list


my_stores = ['Fulham Palace Rd, Hammersmith', 'Crown St, Reading', 'Leavesden Green, Watford']
text = "', '"
print(f'Line 4 should be: [x.split({text})[1] for x in stores]\n')
print(f'If the bug is fixed it will return the next structure: sales + store(without spaces an spliting stores not added correctly)\n')
print(f'get_sql_string returns: {get_sql_string(my_stores)}\n')

print("correct_string function returns: ")
example_strings = ["apple","banana","orange","grape","kiwi","strawberry",
    "blueberry","pineapple","watermelon","peach","apple","kiwi","banana"]
print(correct_string(example_strings))

"""## Part 2 - Pandas Dataframes

### Description

Suppose you have access to two data frames, dept and employee.  The first three rows of these are represented
below.
``` python
dept.head(3)
```
|DEPNO |DNAME      |LOC      |
|------|-----------|---------|      
|12    |Finance    |London   |
|7     |Operations |Edinburgh|
|23    |Marketing  |Paris    |
    
` ` python
employee.head(3)
```
|EMPNO |ENAME JOB       |MGR   |HIREDATE |SAL      |DEPTNO|
|------|----------------|------|---------|---------|------|
|3697  |Smith Developer |5684  |05/05/15 |47000.00 |11    |
|5684  |Davis Manager   |8257  |22/03/09 |63000.00 |11    |
|1891  |Jones Analyst   |5684  |01/09/17 |20000.00 |23    |

Notes:
- MGR is the EMPNO of the Employee whom the observed Employee reports to.
- DEPTNO is a foreign key.

Provide the code needed to:
1. Find the nth largest salary.
2. List the highest salary paid for each job.
3. In which year did most people join the company?  Display the year and the number of Employees.
4. Create a new column with the length of service of the Employees (in the form n years and m months).
5. List all the Employees who have at least one person reporting to them.
6. Calculate and list the Employees who earn more than the average salary of their department.

### Solution

#### Example DataFrame
"""

employee = {
    'EMPNO': [3697, 5684, 1891],
    'ENAME': ['Smith', 'Davis', 'Jones'],
    'JOB': ['Developer', 'Manager', 'Analyst'],
    'MGR': [5684, 8257, 5684],
    'HIREDATE': ['05/05/15', '22/03/09', '01/09/17'],
    'SAL': [47000.00, 63000.00, 20000.00],
    'DEPTNO': [11, 11, 23]
}

employee = pd.DataFrame(employee)

"""#### 1. Find the nth largest salary."""

n = 2
n_biggest = employee['SAL'].sort_values(ascending= False).iloc[n-1]

"""#### 2. List the highest salary paid for each job."""

max_salary_job = employee.groupby('JOB')['SAL'].max()

"""#### 3. In which year did most people join the company?  Display the year and the number of Employees."""

employee['HIREDATE'] = pd.to_datetime(employee['HIREDATE'], format='mixed', dayfirst=True)
number_of_employees = employee['HIREDATE'].dt.year.value_counts().reset_index().max()

"""#### 4. Create a new column with the length of service of the Employees (in the form n years and m months)."""

day = pd.to_datetime('today')
years =  (day - employee['HIREDATE']) // pd.Timedelta(days=365)
months = ((day - employee['HIREDATE']) % pd.Timedelta(days=365)) // pd.Timedelta(days=30)
employee['TIME'] = years.astype(str) + ' years and  ' + months.astype(str) + ' months'

"""#### 5. List all the Employees who have at least one person reporting to them."""

reports = employee[employee['EMPNO'].isin(employee['MGR'])]

"""#### 6. Calculate and list the Employees who earn more than the average salary of their department."""

avg_salary_job = employee.groupby('DEPTNO')['SAL'].mean()
up_to_avg = employee[employee['SAL'] > employee['DEPTNO'].map(avg_salary_job)]

"""## Part 3 - Programming

### Descroption

Suppose you have four comma separated variable files (.csv) available on the folder C:\files
- transactions.csv
- stores.csv
- customer.csv
- products.csv
1. Write a code to sort (ascending order) table customer by customer_id and remove duplicates
2. Create a table transaction_cube merging all tables
3. Create a table which contains the customer_ids that exist in the transactions table but do not exist in the
customer table
4. Create a table called customer_summary with the following variables Customer_id
- Banner
- Category
- Department
- Total_sales
- Total_units
- Average_ticket
- Last_visit
5. Create a table called customer_metrics with the following variables:
- Customer_id
- Month_year
- Banner
- Category
- Department
- Total_sales
- Total_units
- Visits_count (# tickets)
- Visits_count_customer (# tickets regardless of product, category and department)
- Products_count
- Products_count_customer (# products regardless of banner)
- Median_Price
- Distinct_Stores

### Solution

#### Example tables

##### transactions.csv

| customer_id | store_id | date_id    | ticket_id | product_id | unit | sales |
|-------------|----------|------------|-----------|------------|------|-------|
| 3697        | 1        | 2022-01-01 | 1         | 101        | 2    | 10.00 |
| 3697        | 1        | 2022-01-01 | 1         | 102        | 1    | 5.00  |
| 5684        | 2        | 2022-01-02 | 2         | 103        | 3    | 15.00 |
| 1891        | 1        | 2022-01-03 | 3         | 104        | 1    | 8.00  |
| 3697        | 3        | 2022-01-05 | 4         | 105        | 2    | 12.00 |
| 5684        | 2        | 2022-01-05 | 5         | 106        | 1    | 6.00  |
| 1891        | 1        | 2022-01-06 | 6         | 107        | 4    | 20.00 |
| 3697        | 3        | 2022-01-07 | 7         | 108        | 3    | 18.00 |
| 5684        | 2        | 2022-01-08 | 8         | 109        | 2    | 10.00 |
| 1891        | 1        | 2022-01-08 | 9         | 110        | 1    | 5.00  |
| 3697        | 1        | 2023-01-01 | 10        | 111        | 2    | 10.00 |
| 3697        | 1        | 2023-01-01 | 10        | 112        | 1    | 5.00  |
| 5684        | 2        | 2023-01-02 | 11        | 113        | 3    | 15.00 |
| 1891        | 1        | 2023-01-03 | 12        | 114        | 1    | 8.00  |
| 3697        | 3        | 2023-01-05 | 13        | 115        | 2    | 12.00 |
| 5684        | 2        | 2023-01-05 | 14        | 116        | 1    | 6.00  |
| 1891        | 1        | 2023-01-06 | 15        | 117        | 4    | 20.00 |
| 3697        | 3        | 2023-01-07 | 16        | 118        | 3    | 18.00 |
| 5684        | 2        | 2023-01-08 | 17        | 119        | 2    | 10.00 |
| 1891        | 1        | 2023-01-08 | 18        | 120        | 1    | 5.00  |

##### stores.csv

| store_id | store_name | state | banner   |
|----------|------------|-------|----------|
| 1        | Store A    | CA    | Banner A |
| 2        | Store B    | NY    | Banner B |
| 3        | Store C    | TX    | Banner C |

##### customer.csv

| customer_id | age | gender | household_size |
|-------------|-----|--------|----------------|
| 3697        | 30  | M      | 2              |
| 5684        | 40  | F      | 3              |
| 1891        | 25  | F      | 1              |
| 1234        | 35  | M      | 2              |
| 5678        | 50  | F      | 2              |

##### products.csv

| product_id | product_name | brand   | supplier   | department | category       |
|------------|--------------|---------|------------|------------|----------------|
| 101        | Product 1    | Brand A | Supplier A | Food       | Fruit          |
| 102        | Product 2    | Brand B | Supplier B | Food       | Vegetable      |
| 103        | Product 3    | Brand C | Supplier C | Non-Food   | Electronics    |
| 104        | Product 4    | Brand D | Supplier D | Non-Food   | Home Appliances|
| 105        | Product 5    | Brand E | Supplier E | Food       | Meat           |
| 106        | Product 6    | Brand F | Supplier F | Food       | Dairy          |
| 107        | Product 7    | Brand G | Supplier G | Non-Food   | Clothing       |
| 108        | Product 8    | Brand H | Supplier H | Non-Food   | Electronics    |
| 109        | Product 9    | Brand I | Supplier I | Food       | Snacks         |
| 110        | Product 10   | Brand J | Supplier J | Food       | Beverages      |

#### Read CSV
"""

transactions = pd.read_csv("C:/files/transactions.csv")
stores = pd.read_csv("C:/files/stores.csv")
customer = pd.read_csv("C:/files/customer.csv")
products = pd.read_csv("C:/files/products.csv")

"""#### 1. Write a code to sort (ascending order) table customer by customer_id and remove duplicates"""

sort_customer = customer.sort_values(by= 'customer_id').drop_duplicates()

"""#### 2. Create a table transaction_cube merging all tables"""

transaction_cube = pd.merge(transactions, stores, on='store_id', how='left')
transaction_cube = pd.merge(transaction_cube, customer, on= 'customer_id', how= 'left')
transaction_cube = pd.merge(transaction_cube, products, on= 'product_id', how= 'left')

"""#### 3. Create a table which contains the customer_ids that exist in the transactions table but do not exist in the customer table"""

custo_id_transaction = set(transactions['customer_id'])
custo_id_customers = set(customer['customer_id'])
missing = custo_id_transaction - custo_id_customers
missing_table = pd.DataFrame({'customer_id':  list(missing)})

"""#### 4. Create a table called customer_summary with the following variables Customer_id
- Banner
- Category
- Department
- Total_sales
- Total_units
- Average_ticket
- Last_visit
"""

merged = pd.merge(transactions, stores, on='store_id', how='left')
merged = pd.merge(merged, products, on='product_id', how='left')

customer_summary = merged.groupby('customer_id').agg({
  'store_name': 'first',
  'category': 'first',
  'department': 'first',
  'sales': 'sum',
  'unit': 'sum',
  'ticket_id': 'nunique',
  'date_id': 'max'
})
customer_summary['Average_ticket'] = customer_summary['sales'] / customer_summary['ticket_id']

customer_summary = customer_summary.rename(columns={
  'store_name': 'Banner',
  'category': 'Category',
  'department': 'Department',
  'sales': 'Total_sales',
  'unit': 'Total_units',
  'ticket_id': 'Number_of_visits',
  'date_id': 'Last_visit'
})

"""#### 5. Create a table called customer_metrics with the following variables:
- Customer_id
- Month_year
- Banner
- Category
- Department
- Total_sales
- Total_units
- Visits_count (# tickets)
- Visits_count_customer (# tickets regardless of product, category and department)
- Products_count
- Products_count_customer (# products regardless of banner)
- Median_Price
- Distinct_Stores
"""

merged = pd.merge(transactions, stores, on='store_id', how='left')
merged = pd.merge(merged, products, on='product_id', how='left')

merged['date_id'] = pd.to_datetime(merged['date_id'])
merged['Month_year'] = merged['date_id'].dt.to_period('M')

custo_metrics = merged.groupby(['customer_id', 'Month_year']).agg({
    'store_name': 'first',
    'category': 'first',
    'department': 'first',
    'sales': 'sum',
    'unit': 'sum',
    'ticket_id': 'nunique',
    'product_id': 'nunique'
})
custo_metrics.reset_index(inplace=True)
customer_metrics = custo_metrics.rename(columns={
    'store_name': 'Banner',
    'category': 'Category',
    'department': 'Department',
    'sales': 'Total_sales',
    'unit': 'Total_units',
    'ticket_id': 'Visits_count',
    'product_id': 'Products_count'
})

customer_metrics['Visits_count_customer'] = customer_metrics.groupby('customer_id')['Visits_count'].transform('sum')
customer_metrics['Products_count_customer'] = customer_metrics.groupby('customer_id')['Products_count'].transform('sum')
customer_metrics['Median_Price'] = merged.groupby(['customer_id', 'Month_year'])['sales'].median().reset_index()['sales']
customer_metrics['Distinct_Stores'] = merged.groupby(['customer_id', 'Month_year'])['store_id'].nunique().reset_index()['store_id']